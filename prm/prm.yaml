base_model: Qwen/Qwen2.5-Math-7B-Instruct
model_type: AutoModelForTokenClassification
num_labels: 2
tokenizer_type: AutoTokenizer
# Automatically upload checkpoint and final model to HF
# hub_model_id: username/custom_model_name

load_in_8bit: false
load_in_4bit: false
strict: false

liger_rms_norm: true
liger_glu_activation: true

process_reward_model: true
chat_template:
datasets:
  - path: axolotl-ai-co/prm800k_phase_2
    type: stepwise_supervised
    step_separator: "\n\n"
    max_completion_length:
    train_on_last_step_only: false
    splt: train
  - path: axolotl-ai-co/prm800k_phase_1
    type: stepwise_supervised
    step_separator: "\n\n"
    max_completion_length:
    train_on_last_step_only: false
    splt: train
  - path: axolotl-ai-co/Math-Shepherd
    type: stepwise_supervised
    step_separator: "\n\n"
    max_completion_length:
    train_on_last_step_only: false
    splt: train
  
test_datasets:
  - path: axolotl-ai-co/prm800k_phase_2
    type: stepwise_supervised
    step_separator: "\n\n"
    max_completion_length:
    train_on_last_step_only: false
    splt: test
  - path: axolotl-ai-co/prm800k_phase_1
    type: stepwise_supervised
    step_separator: "\n\n"
    max_completion_length:
    train_on_last_step_only: false
    splt: test
  - path: axolotl-ai-co/Math-Shepherd
    type: stepwise_supervised
    step_separator: "\n\n"
    max_completion_length:
    train_on_last_step_only: false
    splt: test
  
output_dir: ./outputs/out
remove_unused_columns: false

sequence_len: 2048
sample_packing: false
eval_sample_packing: false
pad_to_sequence_len: true

wandb_project:
wandb_entity:
wandb_watch:
wandb_name:
wandb_log_model:


gradient_accumulation_steps: 1
micro_batch_size: 16
eval_batch_size: 32
num_epochs: 1
optimizer: adamw_8bit
lr_scheduler: cosine
learning_rate: 0.00005


gradient_checkpointing: true
gradient_checkpointing_kwargs:
use_reentrant: false

train_on_inputs: false
group_by_length: false
bf16: true
fp16:
tf32:
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: false
early_stopping_patience:
resume_from_checkpoint:
local_rank:
logging_steps: 1
xformers_attention:
flash_attention: true
# torch_compile: true

warmup_ratio: 0.1
evals_per_epoch: 10
eval_table_size:
eval_max_new_tokens: 128
saves_per_epoch: 10
debug:
deepspeed: deepspeed_configs/zero1.json
weight_decay: 0.0
fsdp:
fsdp_config:
special_tokens:

