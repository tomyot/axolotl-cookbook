base_model: Qwen/Qwen2.5-Math-7B-Instruct
model_type: AutoModelForTokenClassification
num_labels: 2
tokenizer_type: AutoTokenizer

load_in_8bit: false
load_in_4bit: false
strict: false

liger_rms_norm: true
liger_glu_activation: true
process_reward_model: true
chat_template:
datasets:
  - path: axolotl-ai-co/prm800k_phase_2
    type: stepwise_supervised
    step_separator: "\n\n"
    max_completion_length:
    train_on_last_step_only: false
    splt: train
  - path: axolotl-ai-co/prm800k_phase_1
    type: stepwise_supervised
    step_separator: "\n\n"
    max_completion_length:
    train_on_last_step_only: false
    splt: train

output_dir: ./outputs/out
remove_unused_columns: false

sequence_len: 4096
sample_packing: false
eval_sample_packing: false
pad_to_sequence_len: true

wandb_project:
wandb_entity:
wandb_watch:
wandb_name:
wandb_log_model:


gradient_accumulation_steps: 1
micro_batch_size: 8
eval_batch_size: 64
num_epochs: 1
optimizer: adamw_torch_fused
lr_scheduler: cosine
learning_rate: 5e-5


gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: false

train_on_inputs: false
group_by_length: false
bf16: auto
fp16:
tf32: true

early_stopping_patience:
resume_from_checkpoint:
local_rank:
logging_steps: 1
xformers_attention:
flash_attention: true
torch_compile: true

warmup_ratio: 0.1
evals_per_epoch: 10
eval_table_size:
eval_max_new_tokens: 128
saves_per_epoch: 10
debug:
deepspeed: deepspeed_configs/zero1.json
weight_decay: 0.0
fsdp:
fsdp_config:
special_tokens:


